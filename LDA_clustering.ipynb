{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This script outlines the procedure for LDA clustering (unsupervised) using a TFIDF Vectorizer as embeddings\n",
    "'''\n",
    "\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset.csv')\n",
    "df1 = df['description'].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preprocessing text\n",
    "\n",
    "def preprocess_text(texts):\n",
    "    ans = []\n",
    "    for text in texts:\n",
    "        text = str(text).lower().strip()\n",
    "        cities = ['pune', 'mumbai', 'bangalore', 'bangalor', 'new delhi' ,'new delh', 'delhi ncr', 'delhi', 'hyderabad', 'trivandrum', 'ahmedabad', \n",
    "               'gurgaon', 'jaipur', 'raigarh', 'chennai', 'prague', 'hyderaba', 'vizag', 'noida', 'mysore', \n",
    "               'thane', 'bengaluru', 'kolkatta', 'kolkata', 'dubai', 'varanasi', 'london', 'bhubaneshwar', 'bhubaneswar',\n",
    "               'bengaluru', 'faridabad', 'chandigarh', 'lucknow', 'bhopal', 'ghaziabad', 'kanchipuram', 'indore', \n",
    "               'gwalior', 'udaipur', 'kanyakumari', 'amsterdam', 'andheri', 'jodhpur', 'jamnagar', 'faridabad', 'cochin',\n",
    "               'nasik', 'tirupati', 'san francisco', 'mumba', 'singapore', 'singapor', 'powai', 'surat', 'jodhpur',\n",
    "               'chandigarh', 'gurgaon', 'dhanbad', 'puducherry', 'thiruvanantha']\n",
    "        for city in cities:\n",
    "            text = text.replace(city, '') #'city')\n",
    "        text = re.sub(\"(?i)[.@#]\", \"\", text)\n",
    "        text = re.sub('[^a-zA-Zа-яА-Я0-9]+', ' ', text)\n",
    "        #text = text.translate(str.maketrans('',''), string.punctuation)\n",
    "        text = re.sub(r'\\d+', '', text)\n",
    "        text = text.strip()\n",
    "        ans += [text]\n",
    "    return ans\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Tires where delivered to the garage of my choice,the garage notified me when they had been delivered. A day and time was arranged with the garage and I went and had them fitted,a Hassel free experience.',\n",
       "       'dropped the car off at the time stated on the order and 30 mins later ready to drive away simple great job.',\n",
       "       'Very easy to use and good value for money.', ...,\n",
       "       'I ordered the tyre I needed on line, booked a specified time at a local garage and I had the tyre fitted. All worked very well, to time, and I would use [REDACTED] again. Good price for the tyre, too, as I did a quick search on-line.',\n",
       "       'Excellent service from point of order to fitting. No complaints at all. Thank You.',\n",
       "       'Seamless, well managed at both ends. I would recommend'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = preprocess_text(df1.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_list = list()\n",
    "# print topics based on LDA model\n",
    "def print_topics(model, count_vectorizer, n_top_words):\n",
    "    words = count_vectorizer.get_feature_names()\n",
    "    \n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"\\nTopic #%d:\" % topic_idx)\n",
    "        topic_list.append(\" \".join([words[i] for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "        print(\" \".join([words[i] for i in topic.argsort()[:-n_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words = 'english')\n",
    "X = vectorizer.fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='batch', learning_offset=10.0,\n",
       "             max_doc_update_iter=100, max_iter=10, mean_change_tol=0.001,\n",
       "             n_components=10, n_jobs=-1, n_topics=None, perp_tol=0.1,\n",
       "             random_state=None, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_topics = 10\n",
    "number_words = 2\n",
    "lda = LDA(n_components = number_topics,n_jobs = -1)\n",
    "lda.fit(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic #0:\n",
      "value money\n",
      "\n",
      "Topic #1:\n",
      "easy tyres\n",
      "\n",
      "Topic #2:\n",
      "thank friends\n",
      "\n",
      "Topic #3:\n",
      "forward straight\n",
      "\n",
      "Topic #4:\n",
      "tyres redacted\n",
      "\n",
      "Topic #5:\n",
      "service cheap\n",
      "\n",
      "Topic #6:\n",
      "service good\n",
      "\n",
      "Topic #7:\n",
      "tyres time\n",
      "\n",
      "Topic #8:\n",
      "easy simple\n",
      "\n",
      "Topic #9:\n",
      "friendly service\n"
     ]
    }
   ],
   "source": [
    "print_topics(lda,vectorizer,number_words)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ganeshsamarth\\Anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    }
   ],
   "source": [
    "# the visualization of the clusters can be viewed through the html files in the repo\n",
    "# need to install the pyLDAvis package (pip install pyLDAvis)\n",
    "from pyLDAvis import sklearn as sklearn_lda\n",
    "import pickle\n",
    "import pyLDAvis\n",
    "import os\n",
    "LDAvis_data_filepath = os.path.join('./ldavis_prepared_'+str(number_topics))\n",
    "# # this is a bit time consuming - make the if statement True\n",
    "# # if you want to execute visualization prep yourself\n",
    "LDAvis_prepared = sklearn_lda.prepare(lda, X, vectorizer)\n",
    "#with open(LDAvis_data_filepath, 'w') as f:\n",
    "#        pickle.dump(LDAvis_prepared, f)\n",
    "# load the pre-prepared pyLDAvis data from disk\n",
    "#with open(LDAvis_data_filepath) as f:\n",
    "#    LDAvis_prepared = pickle.load(f)\n",
    "pyLDAvis.save_html(LDAvis_prepared, './ldavis_prepared_'+ str(number_topics) +'.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
